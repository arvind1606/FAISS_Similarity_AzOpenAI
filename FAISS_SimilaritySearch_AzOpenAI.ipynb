{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd563509-e3bf-434f-8742-7f0932016d9d",
   "metadata": {},
   "source": [
    "# impots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819628f5-18d3-4fce-ad81-7f3a475431d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from os import path \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.chat_models import AzureChatOpenAI\n",
    "from openai import AzureOpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d824c-a0b2-45ea-9a87-aeac27ca7d54",
   "metadata": {},
   "source": [
    "# setting env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad1a974-3dcb-4e48-b466-bd095a0619c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ.update({\n",
    "    \"AZURE_OPENAI_API_KEY\": os.getenv(\"openai_api_key\"),\n",
    "    \"AZURE_OPENAI_ENDPOINT\": os.getenv(\"azure_endpoint\"),      \n",
    "})\n",
    "\n",
    "# Azure OpenAI, setting env variables \n",
    "gpt_model = os.getenv(\"openai_model_gpt_name\")\n",
    "embedding_model = os.getenv(\"openai_model_embd_name\")\n",
    "azure_openai_version = os.getenv(\"openai_api_version\")\n",
    "gpt_model = os.getenv(\"openai_model_gpt_name\")\n",
    "embedding_model_deployment = os.getenv(\"openai_model_embd_name\")\n",
    "\n",
    "# blob specifications\n",
    "blob_key = os.getenv(\"blob_key\")\n",
    "connection_string = os.getenv(\"blob_connection_string\")\n",
    "container_name = os.getenv(\"blob_container_name\")\n",
    "\n",
    "# defining LLMs\n",
    "llm = AzureChatOpenAI(openai_api_base=os.getenv(\"openai_api_base\"), temperature=0.5,\n",
    "                      deployment_name=gpt_model, openai_api_version=os.getenv(\"openai_api_version\"))\n",
    "\n",
    "# test LLM\n",
    "x = llm.invoke(\"hello\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c480b4-718f-403e-bb78-e06dcf9e4c7a",
   "metadata": {},
   "source": [
    "# Implementing FAISS vector DB and similarity search\n",
    "This code is designed to process a set of documents and a query, converting the text into numerical embeddings using OpenAI's GPT-3 model through Azure's API service. It then calculates the cosine similarity between the query's embedding and each document's embedding to identify documents that are similar to the query based on a predefined similarity threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf0571e-8e58-45cb-a7f5-d87a15a91621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Index: 0, Similarity Score: 0.9343176002661533\n",
      "Document Index: 1, Similarity Score: 0.9124196831436062\n",
      "Document Index: 2, Similarity Score: 0.8174597176954618\n",
      "Document Index: 3, Similarity Score: 0.8877400628933146\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"openai_api_key\")\n",
    "\n",
    "# Function to encode text using OpenAI GPT-3\n",
    "client = AzureOpenAI(\n",
    "      azure_endpoint = os.getenv(\"openai_api_base\"), \n",
    "      api_key=os.getenv(\"openai_api_key\"),  \n",
    "      api_version=os.getenv(\"openai_api_version\")\n",
    "    )\n",
    "\n",
    "def encode_text(text, engine=os.getenv(\"openai_model_embd_name\")):\n",
    "    response = client.embeddings.create(\n",
    "        model=engine,\n",
    "        input =text,\n",
    "        # max_tokens=50\n",
    "    )\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "# Function to calculate cosine similarity between two vectors\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Function to find similar documents\n",
    "def find_similar_documents(query_embedding, document_embeddings, threshold):\n",
    "    similar_documents = []\n",
    "    for i, doc_embedding in enumerate(document_embeddings):\n",
    "        similarity_score = cosine_similarity(query_embedding, doc_embedding)\n",
    "        if similarity_score > threshold:\n",
    "            similar_documents.append((i, similarity_score))\n",
    "    return similar_documents\n",
    "\n",
    "# Example text documents\n",
    "documents = [\n",
    "    \"This is the first document\",\n",
    "    \"This document is the second document\",\n",
    "    \"And this is the third one\",\n",
    "    \"Is this the first document\",\n",
    "]\n",
    "\n",
    "# Example query\n",
    "query = \"this is the document\"\n",
    "\n",
    "# Encode text documents and query\n",
    "document_embeddings = [encode_text(doc) for doc in documents]\n",
    "query_embedding = encode_text(query)\n",
    "\n",
    "# Find similar documents\n",
    "threshold = 0.5  # Adjust threshold as needed\n",
    "similar_documents = find_similar_documents(query_embedding, document_embeddings, threshold)\n",
    "\n",
    "# Print similar documents\n",
    "for doc_idx, similarity_score in similar_documents:\n",
    "    print(f\"Document Index: {doc_idx}, Similarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c49d32-4bfa-4698-9b27-6bccb5a3cd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
